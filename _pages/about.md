---
permalink: /
# title: "Academic Pages is a ready-to-fork GitHub Pages template for academic personal websites"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a PhD candidate at [Department of Electrical & Computer Engineering, University of Pittsburgh](https://www.engineering.pitt.edu/departments/electrical-computer/), advised by [Dr. Wei Gao](https://sites.pitt.edu/~weigao/). I received my Bachelor's Degree in Automation from [School of the Gifted Young](https://en.scgy.ustc.edu.cn/main.htm), [University of Science and Technology of China](https://ustc.edu.cn) in 2019. 

My research focuses on **mobile sensing** and **AI for healthcare**. I am also interested in applying AI techniques to **robotics**, **IoT** and other practical scenarios.

I am actively seeking an opportunity to leverage my research and analytical skills in industry. View my CV [here](/files/CV_XIANGYU_YIN.pdf). Think my skills could be a good match for your team? Feel free to contact me at <eric.yin@pitt.edu>.

Research Highlights
======
- [**ProGait: A Multi-Purpose Video Dataset and Benchmark for Transfemoral Prosthesis Users**](https://pittisl.github.io/publication/2025-progait/)

  We are collaborating with experts at Rehabilitation Science and Technology, targeting on AI-driven solutions for better prosthesis fitting process. As a pioneer work, we proposed **ProGait**, a multi-purpose video dataset aimed to support multiple vision tasks on prosthesis users, including Video Object Segmentation, 2D Human Pose Estimation, and Gait Analysis. ProGait provides 412 video clips from four above-knee amputees when testing multiple newly-fitted prosthetic legs through walking trials, and depicts the presence, contours, poses, and gait patterns of human subjects with transfemoral prosthetic legs. Our [paper](https://arxiv.org/abs/2507.10223) was acceptted by *ICCV'25* as a **Highlight** and the dataset is available [here](https://huggingface.co/datasets/ericyxy98/ProGait). We are moving forward to leverage the reasoning capability of LLMs/VLMs for a more reliable, consistent, and comprehensive analysis of prosthetic gait, and extend it to general gait analysis.

- [**Smartphone-based Acoustic Sensing for Pulmonary Disease Evaluation**](https://pittisl.github.io/publication/2023-ptease/)

  We developed a mobile health system that turns a commodity smartphone into a fully functional pulmonary examination device that measures the internal physiological conditions of human airways via acoustic sensing through mouth. Since 2020, our integrated AI and sensing systems, namely **PTEase** or Acoustic Waveform Respiratory Evaluation (**AWARE**), have been applied to and tested on more than 400 patients with various pulmonary diseases at the Children's Hospital of Pittsburgh. Our work was published at [SenSys'22 Workshop](https://doi.org/10.1145/3560905.3568437) and [MobiSys'23](https://doi.org/10.1145/3581791.3596854). We also published the [dataset](https://huggingface.co/datasets/ericyxy98/AWARE) of human airway measurements, containing airway measurements of 382 human subjects with various pulmonary diseases and healthy control subjects collected over the past years. This is an ongoing project and we are continually recruiting new human subjects and collecting more comprehensive health information for further analysis.

Publications
======
-	[**ICCV’25**] *Yin, X*., Yang, B., Liu, W., Xue, Q., Alamri, A., Fiedler, G., & Gao, W. (2025). ProGait: A Multi-Purpose Video Dataset and Benchmark for Transfemoral Prosthesis Users. arXiv preprint arXiv:2507.10223. <https://doi.org/10.48550/arXiv.2507.10223>
-	[**MobiSys’25**] Wang, H., Yang, B., *Yin, X.*, & Gao, W. (2025). Never Start from Scratch: Expediting On-Device LLM Personalization via Explainable Model Selection. <https://doi.org/10.48550/arXiv.2504.13938>
-	[**arXiv**] Song, J., Huang, K., *Yin, X.*, Yang, B., & Gao, W. (2024). Achieving Sparse Activation in Small Language Models. arXiv preprint arXiv:2406.06562. <https://doi.org/10.48550/arXiv.2406.06562>
- [**CVPR’25**] Xue, Q., *Yin, X.*, Yang, B., & Gao, W. (2025). Phyt2v: Llm-guided iterative self-refinement for physics-grounded text-to-video generation. In Proceedings of the Computer Vision and Pattern Recognition Conference (pp. 18826-18836). <https://doi.org/10.48550/arXiv.2412.00596>
-	[**MobiCom’25**] Huang, K., *Yin, X*., Huang, H., & Gao, W. (2025). Modality plug-and-play: Runtime modality adaptation in LLM-driven autonomous mobile systems. In ACM MobiCom. <https://sites.pitt.edu/~weigao/publications/mobicom25_mpnp.pdf> (Co-primary author)
-	[**MobiCom’24**] Huang, K., *Yin, X.*, Gu, T., & Gao, W. (2024). Perceptual-Centric Image Super-Resolution using Heterogeneous Processors on Mobile Devices. In Proceedings of the 30th Annual International Conference on Mobile Computing and Networking (pp. 1361-1376). <https://doi.org/10.1145/3636534.3690698>
-	[**MobiSys’23**] *Yin, X.*, Huang, K., Forno, E., Chen, W., Huang, H., & Gao, W. (2023). PTEase: Objective Airway Examination for Pulmonary Telemedicine using Commodity Smartphones. In Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services (pp. 110-123). <https://doi.org/10.1145/3581791.3596854>
-	[**CML-IOT’22/SenSys'22**] *Yin, X.*, Huang, K., Forno, E., Chen, W., Huang, H., & Gao, W. (2022). Out-Clinic Pulmonary Disease Evaluation via Acoustic Sensing and Multi-Task Learning on Commodity Smartphones. In Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems (pp. 1182-1188). <https://doi.org/10.1145/3560905.3568437> (Best Paper Award)

Education
======
- Ph.D., Electrical & Computer Engineering, Swanson School of Engineering, University of Pittsburgh (2019-Present)
- B.Eng., Automation, School of the Gifted Young (少年班学院), University of Science and Technology of China (2015-2019)
